{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZx0W8w7UzBT"
   },
   "source": [
    "## Sample Quiz\n",
    "\n",
    "ADNOC is conducting oil reserve exploration across UAE. They predict whether oil is present in a given location using a sophisticated device which works in the following way: once the device is activated, it returns a signal which is a real number.\n",
    "\n",
    "Studies have found that when oil is not present, the signal follows Laplace distribution with mean $-1$, and scale $1/2$; that is, if $X$ denotes the random signal, then $X$ follows the density\n",
    "$$\n",
    "f_0(x) = p(x|\\text{no oil}) = \\exp\\left(-\\frac{|x+1|}{2}\\right).\n",
    "$$\n",
    "When the location has oil, the density of the signal follows Laplace distribution with mean $5$ and scale $1/2$, i.e.\n",
    "$$\n",
    "f_1(x) = p(x|\\text{oil}) = \\exp\\left(-\\frac{|x-5|}{2}\\right).\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BEwTMA5XpmW"
   },
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QwngcLOmhzud"
   },
   "outputs": [],
   "source": [
    "#Run this cell to import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdXizrv2CX9o"
   },
   "source": [
    "**Task 1 [0.5 point]:** Implement the functions $f_0$ and $f_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nux3ulXL_q6X"
   },
   "outputs": [],
   "source": [
    "def f_0(x):\n",
    "  #Return f_0(x)\n",
    "  return np.exp(- np.abs(x + 1) / 2)\n",
    "\n",
    "def f_1(x):\n",
    "  #Return f_1(x)\n",
    "  return np.exp(- np.abs(x - 5) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJzYAZK9aNZ3"
   },
   "source": [
    "Our goal in this part is implementing the *optimal binary predictor* for whether the drilling at a given location is viable.\n",
    "\n",
    "\n",
    "Each drilling incurs a cost of  2  million Dirhams. If after the drilling the oil is found, the company earns  102  million Dirhams. \n",
    "\n",
    "Thus, if we denote the absence of oil with $0$ and presence of oil with $1$, following the notation from the course we have\n",
    "\\begin{align*}\n",
    "&loss(0, 0) = 0,\\\\ &loss(0, 1) = 0, \\\\ &loss(1, 0) = 2 \\cdot 10^6,\\\\ &loss(1, 1) = -10^8.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Previous experience has shown that the probability of oil presence *prior to any measurement* is equal to $0.1$, so $p_0 = 0.9$, and $p_1 = 0.1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9fEzZ8UgK9M"
   },
   "source": [
    "**Task 2 [0.5 point]:** Implement the function which computes \n",
    "$$\n",
    "\\log\\mathcal{L}(x) = \\log\\left(\\frac{f_1(x)}{f_0(x)}\\right).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VIDNtXxRfO22"
   },
   "outputs": [],
   "source": [
    "def log_L(x):\n",
    "  #Return log L(x)\n",
    "  return -np.abs(x - 5) / 2 + np.abs(x + 1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmlY1e4L9sv-"
   },
   "source": [
    "**Task 3 [0.5 point]:** By equation $(12)$ from slide $103$, the optimal binary predictor outputs $1$ if and only if \n",
    "$$\n",
    "\\log \\mathcal{L}(x) \\geq \\log\\left(\\frac{p_0(loss(1, 0) - loss(0,0))}{p_1(loss(0,1) - loss(1, 1))}\\right).\n",
    "$$\n",
    "\n",
    "Using this, implement the function drilling() which implements the optimal binary predictor for the problem in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iQt19KtiZxOw"
   },
   "outputs": [],
   "source": [
    "def drilling(x):\n",
    "  return (log_L(x) >= np.log(9) + np.log(2 / 10 ** 2)).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrjyXHJTBfG0"
   },
   "source": [
    "**Task 4 [0.5 point]:** Test the function drilling for $x = -1,\\text{ } 0,\\text{ } 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InxtCiamASNI",
    "outputId": "68db2a51-fe1a-4580-c177-96369d8afa06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in [-1, 0, 1]:\n",
    "  print(drilling(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "In this part, we will implement the Perceptron algorithm with the data as generated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "n = 100\n",
    "d = 5\n",
    "X = rng.standard_normal((n, d))\n",
    "Y = rng.binomial(1, 1/2, n)\n",
    "Y = 2 * Y - 1\n",
    "\n",
    "X = np.concatenate((X, Y.reshape(-1, 1)), axis=1)\n",
    "Q, _ = np.linalg.qr(rng.standard_normal((d + 1, d + 1)))\n",
    "X = X @ Q\n",
    "\n",
    "# Try to think why are this data separable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5 [1 point]:** Implement the Perceptron algorithm by filling in the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron update rule\n",
    "def update(w, X, y, i):\n",
    "    x_i, y_i = X[i], y[i]\n",
    "    if y_i * np.dot(w, x_i) < 1:\n",
    "        w += y_i * x_i\n",
    "    else:\n",
    "        w += 0\n",
    "    return w\n",
    "\n",
    "# Empirical risk\n",
    "def empirical_risk(w, X, Y):\n",
    "    return np.mean(np.maximum(0, 1 - Y * (np.dot(X, w))))\n",
    "\n",
    "# Correct predictions\n",
    "def correct_predictions(w, X, Y):\n",
    "    return np.mean(Y * (np.dot(X, w)) >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is trained in 184 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Test the implementation\n",
    "random_seed = 123\n",
    "max_iter = 1000\n",
    "eps = 1e-8\n",
    "\n",
    "# Intialize the model\n",
    "w = np.zeros(X.shape[1])\n",
    "losses = []\n",
    "rng = np.random.default_rng(random_seed)\n",
    "\n",
    "for j in range(max_iter):\n",
    "    losses.append(empirical_risk(w, X, Y))\n",
    "    i = rng.integers(0, len(X))\n",
    "    w = update(w, X, Y, i)\n",
    "    if losses[-1] < eps:\n",
    "        losses.append(empirical_risk(w, X, Y))\n",
    "        break\n",
    "        \n",
    "assert losses[-1] < eps\n",
    "assert correct_predictions(w, X, Y) == 1\n",
    "\n",
    "print(f\"Model is trained in {j+1} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6 [1 point]:** Update the implemntation above to collect indices of misclassified points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron update rule with missclassified flag\n",
    "def update(w, X, y, i):\n",
    "    x_i, y_i = X[i], y[i]\n",
    "    if y_i * np.dot(w, x_i) < 1:\n",
    "        missclassified = True\n",
    "        w += y_i * x_i\n",
    "    else:\n",
    "        missclassified = False\n",
    "        w += 0\n",
    "    return w, missclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is trained in 184 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Test the implementation\n",
    "random_seed = 123\n",
    "max_iter = 1000\n",
    "eps = 1e-8\n",
    "\n",
    "# Intialize the model\n",
    "w = np.zeros(X.shape[1])\n",
    "losses = []\n",
    "rng = np.random.default_rng(random_seed)\n",
    "M = set()\n",
    "samples = []\n",
    "\n",
    "for j in range(max_iter):\n",
    "    losses.append(empirical_risk(w, X, Y))\n",
    "    i = rng.integers(0, len(X))\n",
    "    samples.append(i)\n",
    "    w, missclasified = update(w, X, Y, i)\n",
    "    if missclasified:\n",
    "        M.add(i)\n",
    "    if losses[-1] < eps:\n",
    "        losses.append(empirical_risk(w, X, Y))\n",
    "        break\n",
    "        \n",
    "assert losses[-1] < eps\n",
    "assert correct_predictions(w, X, Y) == 1\n",
    "\n",
    "print(f\"Model is trained in {j+1} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7 [1 point]:** Assert that by removing all the points that does not belong to $M$, the final solutions remains the same if we preserve the sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing complement of M does not change the model.\n"
     ]
    }
   ],
   "source": [
    "w_full_data = w.copy()\n",
    "\n",
    "# Intialize the model\n",
    "w = np.zeros(X.shape[1])\n",
    "losses = []\n",
    "\n",
    "for i in samples:\n",
    "    losses.append(empirical_risk(w, X, Y))\n",
    "    if i in M:\n",
    "        w, _ = update(w, X, Y, i)\n",
    "    if losses[-1] < eps:\n",
    "        losses.append(empirical_risk(w, X, Y))\n",
    "        break\n",
    "\n",
    "assert np.linalg.norm(w - w_full_data) < 1e-10\n",
    "\n",
    "print(\"Removing complement of M does not change the model.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
